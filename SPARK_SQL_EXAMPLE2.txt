1.	Count the number of flights which have the unique ordered pair of source and destination, i.e., for two flights, either the origin differs or destination differs.

2.	For each year fetch the airport code that has the maximum number of outgoing flights and order the results in descending order w.r.t the number of outgoing flights.

3.	Year-wise count the total number of Cancelled flights due to bad Weather, order the results w.r.t the count.


Use the dataset present at the location:
(hdfs:///bigdatapgp/common_folder/assigment6/airline_data/)
###################################################################

// In Scala
import org.apache.spark.sql.types._
import org.apache.spark.sql._
import org.apache.spark.sql.functions._

val schema = StructType(Array(
    StructField("_id", IntegerType, true),
    StructField("Year", StringType, true),
    StructField("Month", StringType, true),
    StructField("DayofMonth", StringType, true),
    StructField("DayOfWeek", StringType, true),
    StructField("DepTime", StringType, true),
    StructField("CRSDepTime", StringType, true),
    StructField("ArrTime", StringType, true),
    StructField("CRSArrTime", StringType, true),
    StructField("UniqueCarrier", StringType, true),
    StructField("FlightNum", StringType, true),
    StructField("TailNum", StringType, true),
    StructField("ActualElapsedTime", StringType, true),
    StructField("CRSElapsedTime", StringType, true),
    StructField("AirTime", StringType, true),
    StructField("ArrDelay", StringType, true),
    StructField("DepDelay", StringType, true),
    StructField("Origin", StringType, true),
    StructField("Dest", StringType, true),
    StructField("Distance", StringType, true),
    StructField("Taxiin", StringType, true),
    StructField("TaxiOut", StringType, true),
    StructField("Cancelled", StringType, true),
    StructField("Cancellation_Code", StringType, true),
    StructField("Diverted", StringType, true),
    StructField("Carrier_Delay", StringType, true),
    StructField("WeatherDelay", StringType, true),
    StructField("NASDelay", StringType, true),
    StructField("Security_Delay", StringType, true),
    StructField("LateAircraftDelay", StringType, true)    
  ))

var file = "maprfs:///data/flights.json"

val df = spark.read.format("csv").option("inferSchema", "false").schema(schema).load(file)

case class Flight(_id: Integer, Year: String, Month: String, DayofMonth: String, DayOfWeek: String, DepTime: String, CRSDepTime: String, ArrTime: String,CRSArrTime: String, 
UniqueCarrier: String, FlightNum: String, TailNum: String, ActualElapsedTime: String, CRSElapsedTime: String, AirTime: String, ArrDelay: String, DepDelay: String, Origin: String, Dest: String, Distance: String,
Taxiin: String, TaxiOut: String, Cancelled: String, Cancellation_Code: String, Diverted: String, Carrier_Delay: String, WeatherDelay: String, NASDelay: String, Security_Delay: String, LateAircraftDelay: String) extends Serializable

val df = spark.read.format("csv").option("inferSchema", "false").schema(schema).load(file).as[Flight]

// val schema = "date STRING, delay INT, distance INT, origin STRING, destination STRING"

// cache DataFrame in columnar format in memory
df.cache

// create Table view of DataFrame for Spark SQL
df.createOrReplaceTempView("flights")


1.	Count the number of flights which have the unique ordered pair of source and destination, i.e., for two flights, either the origin differs or destination differs.
=================================================================================================================================================================================


df.filter($"Origin" != $"Dest").groupBy($"FlightNum").count.orderBy(desc( "count")).show



2.	For each year fetch the airport code that has the maximum number of outgoing flights and order the results in descending order w.r.t the number of outgoing flights.
=================================================================================================================================================================================== 


Here Origin = Origin IATA airport code (International Air Transport Association)

%sql
flights_delta = spark.read.format("delta").load("/mnt/home/edureka_918210/airline_data/Airline.csv")

display(flights_delta.groupBy("Year","Origin").max(count("Origin").alias("MaxFlights")).orderBy("MaxFlights", ascending=True))

3.	Year-wise count the total number of Cancelled flights due to bad Weather, order the results w.r.t the count.
=======================================================================================================================
// Spark SQL

spark.sql("select Year, count(Cancelled) from flights group by Year").show
df.select($"Year",$"Count").orderby(desc("Year")).show

